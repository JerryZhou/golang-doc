# Regular Expression Matching in the Wild

## Introduction

本系列的前面两篇文章[Regular Expression Matching Can Be Simple And Fast](https://swtch.com/~rsc/regexp/regexp1.html),  [Regular Expression Matching: the Virtual Machine Approach](https://swtch.com/~rsc/regexp/regexp2.html)，分别对基于DFA和NFA的正则匹配算法做了解析，为了说明解析过程的原理，在正则规则上我们采用了从简原则。这篇文章从工程实作角度来描述具体的实现过程。

2006年的我花了一个暑假做了一个[Code Search](http://www.google.com/codesearch)项目，让程序员可以用正则表达式来搜索代码。也就意味着，可以让你在全球的所有开源代码里面执行[grep](http://plan9.bell-labs.com/magic/man2html/1/grep)操作。我们开始打算采用PCRE做我们的正则匹配引擎，但后面了解到他采用的是回溯算法，会导致潜在的[指数时间复杂度](https://swtch.com/~rsc/regexp/regexp1.html)，以及相应的运行时栈溢出。因为代码搜索的服务是面向所有互联网用户的，如果采用PCRE，就会给我们带来攻击风险导致服务不可用。在排除PCRE以外的一个选择，就是我自己来写一个，新的这个匹配引擎是基于Ken Thompson的[开源版本的grep](http://swtch.com/usr/local/plan9/src/cmd/grep/)，这个grep采用的是基于DFA算法的。

在接下来的三年，我实现了一个新的匹配后端替换了grep里面相应的代码，扩展了原有的功能到支持POSIX的标准grep。这个新版本就是RE2, 提供与PCRE类似的C++的接口，而且功能也和PCRE基本保持一致，同时还保证了线性时间复杂度，同时不会出现栈溢出的问题。RE2现在被广泛的运用在Google里面，包括Code-Search,以及一些内部的系统比如[Sawzall](http://labs.google.com/papers/sawzall.html)和[Bigtable](http://labs.google.com/papers/bigtable.html)。

到2010年三月，RE2变成了一个[开源](http://code.google.com/p/re2/source/browse/LICENSE)项目。这篇文章就是对RE2的源代码进行统领说明的，在本文中会详细展示前面两篇文章中提到的技术是怎么在RE2里面实作的。

## Step 1: Parse

在早期，正则表达式的[语法非常简单](http://www.freebsd.org/cgi/man.cgi?query=grep&apropos=0&sektion=1&manpath=Unix+Seventh+Edition&format=html)，回想一下第一篇文章里面提到：concatenation, repetition, 和 alternation。还有字符分类：普通字符，+, ? 等元字符，以及位置断言符 ^ 和 $。表面看起来，今天的程序员，面对的正则表达式字符分类要丰富得多，但现在的正则表达式解析器一个重要的工作就是把输入转义到前面的那些基础概念上去。RE2的解析器定义了一个正则表达式结构体，定义在[regexp.h](http://code.google.com/p/re2/source/browse/re2/regexp.h#103)文件中，他和原有的egrep语法非常接近，只是有多了少量的几个特殊情形：

1. 字面字符串由kRegexpLiteralString节点表述，这样比串联一组kRegexpLiteral节点省内存。
2. 重复链接操作由kRegexpRepeat节点表述，虽然单靠这个节点不能完成重复语义。我们后面会看到这个节点具体是怎么编译的。
3. 字符类不是通过简单的一组范围或者一个位图来表述，而是平衡二叉树的节点范围来表述，这种方式会带来复杂度的提升，但对于处理Unicode字符类的时候却非常的关键。
4. 任意字符由一个特殊的节点类型来表述，和任意字节操作符一样。但任意字符和任意字节在RE2里面，在匹配UTF8的输入文本的时候，因为RE2的默认操作模式会有一点点差异。
5. 大小写不敏感的匹配是通过特殊的标志位来实现的。对于ASCII字符来说和那种多字节字符还不一样，比如 (?i)abc，被解析为 abc 和一个大小写敏感标志位，而不是解析为 `[Aa][Bb][Cc]`。RE2开始的时候，其实解析为后者的。对于后者来说比较消耗内存，特别是哪些tree-based的字符类。

RE2的解析器实现在[parse.cc](http://code.google.com/p/re2/source/browse/re2/parse.cc#1539)。这是一个纯手写的解析器，主要是为了避免两个事情，一个是避免对另外一个解析器生成器的依赖，另外一个是现在的正则表达式规则已经不规则了，有太多的特殊设计。这里实现的解析器，没有使用递归下降，因为递归的深度会带来潜在的指数增长和栈溢出问题，特别是在多线程环境下。这里的解析器维持了一个解析栈，和LR(1)语法接下器做的类似。

有一个时期让我蛮惊讶的，对于同样的正则表达式不同的用户居然会有如此多不同的写法。例如，对于一个单字符类，比如-[.]，或者 \\. ,可选项用 a|b|c|d 而不是 [a-d]。接下器里面会要处理这些情况，并且选用最有效的形式来表达相应的匹配语义，而不是把这种情况传递到第二阶段。



## Walking a Regexp

在解析完正则表达式后，接下来就是处理过程了。解析的结果是一个标准的树结构，通常树结构都是用标准的递归遍历。不幸的是，我们这里并不能确保我们是否有足够的栈空间来做递归遍历。比如一些别有用心的用户可能会写出如下的正则表达式`((((((((((a*)*)*)*)*)*)*)*)*)*)*`(或者是更大的)直接就导致懵逼的栈溢出。所以，遍历过程，我们采用显式栈的方式。这里[Walker](http://code.google.com/p/re2/source/browse/re2/walker-inl.h#22)有一个模板隐藏了栈管理，让这种限制条件更可操作。

回想一下，我再想解析结果是树的形式，然后我们通过Walker的方式来遍历，也许这整个处理过程就是错误的。如果递归在这里是不允许的，我们或许就应该从根上来避免递归的表述形式，可以把解析结果存储在[Thompson's 1968 论文](http://swtch.com/~rsc/regexp/regexp1.html#thompson)里面提到的[逆波兰式](http://en.wikipedia.org/wiki/Reverse_Polish_notation)，如[示例代码](http://swtch.com/~rsc/regexp/nfa.c.txt)里面一样。如果RPN形式记录了最大的栈深度，那么在遍历的时候，我们就可以申请确定大小的栈，然后依次对表达式进行线性的扫描。



## Step 2:Simplify

接下来的补助就是简化，会重写那些复杂操作符为尽可能简单的，让后续的处理更加容易。随着时间的迁移，在RE2里面简化这个步骤的代码大部分都被挪到第一步解析器里面去了，因为简化步骤越早做越好，会减少大量的临时内存消耗。现在在简化里面还有最后的一个工作就是简化重复计数的正则表达式为一个基本的序列。比如把 `x{2,5}`简化为`xx(x(x(x)?)?)?`。



## Step 3: Compile

一旦正则表达式已经变成只使用第一篇文章里面提到的那些基础操作符以后，我们就可以用[这里](https://swtch.com/~rsc/regexp/regexp1.html#compiling)提到的技术进行编译了。我们也很容易的了解到这里的[编译规则](http://code.google.com/p/re2/source/browse/re2/compile.cc#17)。

在RE2的编译器里面有一个非常有意思的技巧，是我从Thompson的grep那里学来的。他会把UTF8的编译进一个自动机，也就是一次只读取一个字节。也就是状态机就是用的UTF8解码器来读取输入数据的。比如，为了匹配码点再0000到FFFF的Unicode字符，自动机会接受如下的字节序列：

```
[00-7F] 							 // code points 0000-007F
[C2-DF][80-BF]						  // code points 0080-07FF
[E0][A0-BF][80-BF]					  // code points 08000-0FFF
[E1-EF][80-BF][80-BF]				  // code points 1000-FFFF
```

这里列举处理，并不是说编译的时候选择其中一种，对于[80-BF]这种通用后缀也是可以被拎出来的。上述的实际编译形式应该是如下图所示：

![](https://swtch.com/~rsc/regexp/utf3.png)

上面的例子其实是一个具备明显优势的规则表达式。下面的状态机匹配的全域的Unicode，从0000000-10FFFF:

![](https://swtch.com/~rsc/regexp/utf4.png)

比前面的状态机要大，但依然是规则度很高的。在实际的情况下，也由于Unicode的发展历史，字符类其实面临的是不规则的情况。比如， \p{Sc}, 当前的符号码点就会是如下的状态机：

![](https://swtch.com/~rsc/regexp/cat_Sc.png)

这个符号类在本文中来看，到目前为止已经是最复杂的了，但实际情况下，还有其他的字符类比这个还要复杂；比如，[`\p{Greek}`](https://swtch.com/~rsc/regexp/script_Greek.png)(所有希腊脚本)或者 [`\p{Lu}`](https://swtch.com/~rsc/regexp/cat_Lu.png)(所有大写字符)。

编译的结果其实是一个指令图，从描述上更加和第一篇文章里面的图更加贴近，但打印出来看其起来是一个虚拟机的执行程序。

编译成UTF-8的形式会让编译器更加复杂，但是会让匹配引擎执行更快：每次都只处理一个字节。对于每次只处理一个字节，也让很多匹配器更加容易处理匹配过程。



## Step 4: Match

到现在为止，前面所有的讨论都是构建一个RE2。在构建好RE2以后，就可以用来执行匹配操作。从使用者角度来看，只有两个方法：`RE2::PartialMatch`用来在输入文本里面找到第一个匹配的子串，和`RE2::FullMatch`用来完整搜索整个输入字符串的。但从RE2的实现角度，这里是有非常多可以讨论的地方。RE2主要处理4类基本的正则表达式匹配问题：

1. 正则表达式是否和整个输入字符串匹配？

   > RE2::FullMatch(s, "re")
   >
   > RE2::PartialMatch(s, "^re$")

2. 正则表达式是否匹配输入字符串里面的一个子串？

   > RE2::PartialMatch(s, "re")

3. 如果正则表达式匹配字符串中的一个子串，那么具体是哪个子串？

   > RE2::PartialMatch(s, "(re)", &match)

4. 如果正则表达式匹配字符串中的一个子串，那么具体是哪个子串，同时相应的子匹配是什么？

   > RE2::PartialMatch(s, "(r+)(e+)", &m1, &m2)

接下来会对上面的4中情况分别做描述。从使用者的角度，提供4种匹配使用看起来应该已经足够。但从实现角度来看的话，并不是这样来区分的，而且前面的问题其实是比后面的问题有更加高效手段实现的(只判定是否匹配肯定其实相对子匹配来说要简单一些)。



## _Does the regexp match the whole string ?_

> RE2::FullMatch(s, "re")
>
> RE2::PartialMatch(s, "^re$")

这个问题，其实在第一篇文章里面我们就有解析。在第一篇文章中，我们看到通过运行时生成一个简单的DFA来达到目的。[RE2也是采用的DFA](http://code.google.com/p/re2/source/browse/re2/dfa.cc#5)来解决这个问题，只是这里的DFA在内存使用和线程安全上有更多的改进，主要来自如下的两个修改。

_Be able to flush the DFA cache_一个给定的正则表达式和输入文本，是可能导致每处理一个字节，都需要DFA创建一个新的状态的。对于大型的输入文本来说，状态是一个快消品。在RE2的DFA里面，他的状态会有一个[cache来管理](http://code.google.com/p/re2/source/browse/re2/dfa.cc#1081)。这样让DFA的整个匹配过程对于内存来说是恒定的。

_Don't store state in the compiled program_在DFA第一篇文章里面，我们用一个整形的序列号字段在编译程序里面来追踪状态是否出现在特定的列表里面(s->lastlist和listid)。这个追踪手段让我们把状态加入列表的时候可以在常量时间里面进行去重操作。在一个多线程的程序里面，在线程之间共享同一个RE2对象，这个对象来唯一的管理序列号，这样就有引入了锁。但我们肯定是希望在常量时间内能处理列表的插入去重操作的。幸运的是，有一个数据结构稀疏集合就是被设计用来干这个事情的。RE2实现了这个数据结构[SparseArray](http://code.google.com/p/re2/source/browse/util/sparse_array.h)，详情可以参考这个[文章](http://research.swtch.com/2008/03/using-uninitialized-memory-for-fun-and.html)。



## _Does the regexp match a substring of the string ?_

> RE2::PartialMatch(s, "re")

上一个问题问的是正则表达式是否匹配整个字符串；这个问题问的是是否匹配任意的子串。我们可以把这个问题通过对正则表达式改写为 `.*re.*`降级为上一个问题，但更优的改写是 `.*re`，当匹配发生的时候，然后把余下的部分裁剪掉就得到匹配的子串。

_找到第一个匹配的字节_。从DFA或者编译程序里面可以分析每一个起始的字节他可能的匹配状态。在这种情况下，DFA寻找一个新的起点的时候，不需要对每一个字符都执行DFA的循环，可以直接通过[`memchr`来查找匹配的起始字符](http://code.google.com/p/re2/source/browse/re2/dfa.cc#1289)，而且`memchr`通常都会使用特定平台的硬件指令进行优化。

_尽早退出循环_，当问询的指数是否存在局部匹配的时候(例如问在字符串`ccccabbbbbddd?`里面是否存在子串匹配`ab+`)，DFA可以在发现了`ab`后就停止匹配过程。修改DFA的的循环，在[检查每一个字节的匹配情况](http://code.google.com/p/re2/source/browse/re2/dfa.cc#1397)的时候，他可以尽可能快的停止匹配过程，只要发现了任何一个匹配项，而不用去找到确定的最长匹配是什么。记住，这里我们可以这么干，是因为调用者只关心是否存在子串匹配，而不关心匹配的子串是什么。

这样描述，看起来这里的DFA与解决上一个问题的DFA稍有不同啊。DFA的代码是一个简单的循环，循环里面会通过一个flags区控制相应的行为，看是否需要查找第一个有效的字节，是否需要尽早退出循环等。在2008年，我写第一个DFA代码的时候，在内循环里面检查flags，效率很低。后面我写了一个[内联的搜索循环函数](http://code.google.com/p/re2/source/browse/re2/dfa.cc#1254)，根据三个布尔变量特化出8个不同类型的循环。每一个循环都根据自身要解决的问题做特殊的优化，外面调用的时候就不是调用原来的DFA循环，而是代用这8个循环里面的一个。我注意到最新版本的g++，已经不支持对InlineSearchLoop函数进行内联操作了，因为这个函数太大的缘故。所以现在的代码里面已经没有8份不同情况的搜索循环了。当然依然也是可以通过模板函数来实现8个不同循环的特化的，只是从现在来看已经意义不大，我尝试过，但发现特化的代码并没有带来效率的提升。



## _Does the regexp match a substring of the string? If so, where?_

> RE2::PartialMatch(s, "(re)", &match)

调用者增加了需求，现在调用者想知道匹配的子串具体的位置是什么。当然我们可以直接使用NFA来达到目的，只是需要承担一定的效率为代价。我们这，依然是通过在DFA的基础上做修改，来提取相应的信息。

_找到endpointd的确切位置_，标准的DFA里面，每一个状态对应的都是一组无需的NFA状态。如果这个地方，我们把DFA状态对应的NFA状态集弄成局部有序的，这样我们就可以比较NFA状态之间的优先级，DFA可以确定相应的匹配点的截止位置。

在POSIX的规则里面，起始状态在输入里面的位置越前，优先级越高。比如一个DFA状态对应到五个NFA状态{1,2,3,4,5}，他们的优先级可能是 {1,4}{2,3,5}：从1或者4状态开始的匹配比从2,3或者5开始的匹配优先级更高。这里主要的优先级比较是根据"leftmost longest"里面的"leftmost"，最左原则。为了实现"longest"的要求，每一次匹配发现的时候，DFA会记录下他，并且只会继续执行那先比当前这个状态优先级更高的状态。一旦所有状态都匹配完成后，最后一个记录的匹配位置就是满足"leftmost longest"要求的匹配位置。

在Perl-style的规则里面，对于"leftmost"这个的语义的处理是一样的，只是Perl不处理"longest"语义。在处理NFA状态排序的是，他会把状态处理成完整有序的：没有任何的两个状态具备一样的优先级。比如在处理`a|b`的时候，a就具备比b高的优先级。比如对于`x*`来说就是循环处理可选项，一致优先尝试匹配另外一个x. 上述两种情况，关于节点的分裂如第一篇文章所示意的一样：

![](https://swtch.com/~rsc/regexp/fig16.png)

![](https://swtch.com/~rsc/regexp/fig18.png)

分割的时候，上面分支的优先级更高。对于一个非贪婪的可选操作符来说，就是相当于把优先级反转一下。

为了找到一个Perl匹配的结束点，每一次一个匹配发现的时候，DFA都需要记录下来，同时继续执行那些比当前状态优先级更高的状态匹配。一旦所有状态都匹配完成了，最后一个记录的位置就必然是优先级最高匹配达到的位置。

很好：现在我们知道匹配在哪里结束了。但调用者要要知道是整个子串的位置，肯定得要知道从哪里开始的。我们怎么来做这个呢？

_逆序运行一遍DFA找到起始位置_。我们在学习正则表达式相关计算理论的时候，一个很经典的练习就是证明如果把正则表达式的所有连接操作反过来得到一个新的正则表达式(比如 [Gg]oo+gle逆序变成elgo+o[Gg])，这个新的正则表达式是否匹配到原来正序时候匹配的字符串的相应逆序字符串。在正则表达式的很多联系中不见得都有实用价值，但这个练习确实有。DFAs只会包裹匹配结束的位置，如果我们反向运行DFA，这个反向得到的结束位置就会是正序的起始位置，因为我们同时也会逆序输入字符串啊。

我们编译正则表达式的的逆序后，我们从前面发现的结束点逆序输入字符，然后在新的输入字符上查找longest的结束点。这样我们找到的结束点就相当于是正序里面的leftmost匹配，也就是匹配的开始位置。



## _Does this regexp match this string? If so, where ? Where are the submatches ?_

> RE2::PartialMatch(s, "(r+)(e+)", &m1, &m2)

这是关于正则表达式调用者能够提出的最难回答的问题。

这个问题的前面两个部分可以用DFA来解答。第三部分只能通过直接的NFA模拟才能解答了。DFA的运行效率非常高，我们用DFA先来做整体的匹配，同时通过第一遍的DFA匹配，可以减少NFA需要处理的输入字符的量，这个对于在一个巨量的字符里面搜寻小段字符的时候会非常有用，同时在DFA没有搜索匹配的时候，是不需要通过NFA去搜索了，这么搜索不到情形在实际中还是蛮常见的。

一旦通过DFA找到了匹配位置，就可以用NFA来查找子匹配的匹配边界了。NFA的运行效率是线性的(与正则表达式的大小以及输入文本的大小成线性时间复杂度)，但由于在运行的过程中需要记住子匹配的具体范围，需要拷贝子匹配的边界的集合，所以在很多情况下这种运行方式导致比PCRE的这种回溯遍历的方式要更慢。为了保证在最坏的情况下的性能，对于普通情况下的运行会所到一些些影响(详情可以参考[Regular Expression Matching: the Virtual Machine Approach](https://swtch.com/~rsc/regexp/regexp2.html))。

存在一些重要的常见案例，我们可以用特殊的自定义代码处理，而不用通过进入通用的NFA模拟来保证执行效率。

_**尽可能的使用one-pass的NFA**_。在NFA里面消耗蛮多时间来追踪子匹配的边界(特别是需要拷贝这些边界)，其实我们是能够鉴别大部分的正则表达式，不管输入的字符串是什么，他们是只需要NFA来保存一组边界位置就可以了。

首先我们来定义什么是**one-pass 正则表达式**，这种表达式具备如下的特征，在一个给定的匹配锚点上，对于每一个字节的输入，只有唯一的跳转选择。比如 `x*yx*`就属于**one-pass**：一直读取x，知道遇到一个y，然后继续读取x。正则表达式表达是内容里面，不会出现那种需要你来选择读取什么或者需要回溯。另外一个例子，`x*x`就不是**one-pass**的：当你读入一个x的时候，你不知道这个x是用来匹配`x*`的，还是用来匹配最后一个`x`的。更多的例子，比如`([^x]*)x(.*)`就是一个**one-pass**；`(.*)x(.*)`不是**one-pass**的。`(\d+)-(\d+)`是one-pass, 而`(\d+).(\d+)`不是。

一个简单的直观方法判定一个正则表达式是不是属于**one-pass**的就是当他的结束是一个可选操作的时候，可选操作是显而易见无歧义的单选。比如x(y|z)是属于**one-pass**的，但(xy|xz)不是。

因为只会有一个可能的跳转状态，对于one-pass的NFA实现来说，就不需要拷贝子匹配的边界值。一个one-pass的匹配引擎执行分两步。在编译节点，[分析程序](http://code.google.com/p/re2/source/browse/re2/onepass.cc#363)需要判定一个是不是属于one-pass的。如果是，需要计算一个数据结构记录在每一个可能的状态以及相应能接收的字节。然后在执行节点one-pass引擎，可以直接遍历输入字符串，通过一个遍历找到相应的匹配(或者发现不匹配)。

_**如果可能使用位状态来实现回溯**_。像类PCRE的这种通过递归避免拷贝子匹配边界集合的回溯实现方法：只需要维持一个子匹配边界集合，在递归的过程中来覆写或者恢复边界集。与之对应的是，这类方法他需要对输入字符进行多次遍历，至少一个NFA状态就需要遍历一次。尽管针对每一个NFA状态需要对字符串的同一部分进行多次遍历，但这里这依然至少一个线性时间复杂度的扫描，因为算法上并没有记住他是否一起遍历过同样的路劲。

位状态回溯的基本方法还是一个标准的回溯算法，手动管理栈，增加了一个位图来追踪和保存那些已经访问过的遍历路径(位图里面保存状态以及相应的字符串位置)。对于一个较小的正则表达式和较小的输入字符串来说，申请和清理一个bitmap比拷贝NFA状态来得快。RE2里面用了[位状态回溯](http://code.google.com/p/re2/source/browse/re2/re2.cc#669)的方法，其中申请的位图是32Kb。

​	_如果所有特殊路径的尝试都不可行，就用[标准的NFA模拟](http://code.google.com/p/re2/source/browse/re2/nfa.cc)_



## Analysis

RE2丢弃了PCRE里面那些不能通过状态机实现的特性(其中最有名的就是反向引用backreferences)。放弃这些难以实现的特性后，RE2可以从理论上来在各种应用场景里面分析正则表达式以及相应的状态机。比如前面在DFA里面用memchr寻找起点，以及判定一个正则是否适用于one-pass等。RE2也提供一些高层的模式分析应用在一些更高层面的检索中。

_**范围匹配**_。[Bigtable](http://labs.google.com/papers/bigtable.html)按照行的名字存储记录，这样就可以通过行的名字快速检索一个范围内的记录。Bigtable 也允许使用方通过正则表达式来对记录进行过滤。这样对于一些客户来说，就可以只通过正则表达式进行检索，而不提供行的范围。对于有这种需求的用户来说，就可以通过RE2来先计算出一个匹配正则表达式的行的范围，然后在给定的范围内进行检索。比如，`(hello|world)+`，[RE2::PossibleMatchRange](http://code.google.com/p/re2/source/browse/re2/dfa.cc#1861)可以计算出可能的匹配范围是[hello, worldworle]。是不是很疑虑，怎么做到的？通过从DFA图的起点状态开始，找到一个具备最小字节值的路径，和一个具备最大字节值的路径。其中单词 worldworle 最后一个字母 e ，不要认为是一个印刷错误啊：worldworldworld < worldworle 但不是 worldworld: PossibleMatchRange 通常需要截断字符，然后才被用于表示匹配范围，当需要截断的时候通常需要做向上取整的操作。

_**子串查询**_。如果你又一个很高效的方法来检查一组字符串是否出现某一个巨量文本里面(比方说，你实现了[Aho-Corasick algorithm](http://en.wikipedia.org/wiki/Aho-Corasick_algorithm)) ，但你的用户希望你能够同时提供正则表达式来检索答案。正则表达式的对于字面检索来说通常通常代表的是一组字面字符串；如果用户的输入字符串能够被简单的分解识别为一组字符串，那么分解的结果就可以丢到字符串搜索器里面取搜索，搜索器的搜索结果就可以用来筛选必要的正则表达式。[`FilteredRE2` class](http://code.google.com/p/re2/source/browse/re2/filtered_re2.h)实现了这个分析能力。给一组正则表达式，他会遍历正则表达式，计算出表达字面串形式的一个布尔表达式，同时返回涉及到的所有字符串。比如 FilteredRE2 可以把`(hello|hi)world[a-z]+foo`翻译成一个布尔表达式`(helloworld OR hiworld) NAD foo`，以及返回相应的字符串列表。给多个正则表达式，FilteredRE2会把每一个正则转译为一个布尔表达式，同时返回所有涉及的字符串。在得到所有相关的字面字符串以后，FilteredRE2也就可以评估每一个表达式，找出相应的正则表达式。这种过滤可以减少无效的正则检索。

上面提到的两种分析的可行性都是依赖在输入的字符串的简洁特征，第一个依赖DFA表达式，第二个使用正则表达式解析器的中间值(Regexp*)。如果再RE2里面允许出现那些不正则特性，那么这里的分析过程就会变得更复杂甚至不可能。



## Internationalization

RE2的正则表达式可接受所有的Unicode序列，能够检索所有UTF-8或者Latin-1编码的文本。在PCRE和其他正则表达式的实现里面会有一些组的命名，比如[[:digit:]]和\d表述包含ASCII，\p{Nd}包含全部的Unicode。对于RE2的挑战是要在兼容实现大范围的Unicode字符集的基础上保持高效性。我们前面有提到一个字符类是用一个平衡二叉树来表述的，但我们需要考虑到要保持库的内存占用尽可能的小，我们的尽可能的压缩Unicode-table在内存的编码表示。

为了达到国际化的目标，RE2里面采用的是Unicode5.2的常规类别(比如 \pN 或者 \p{Lu})和Unicode脚本类别(比如\p{Greek})。如果输入字符不仅仅是ASCII字符，我们就得使用这些Unicode定义的类别(比如 用 \pN 或者 \p{Nd} 来代替 [[:digit]]和\d)。 RE2没有实现其他的Unicode 类别(详见 [Unicode Technical Standard #18: Unicode Regular Expressions](http://www.unicode.org/reports/tr18/))。在Unicode的分组表里面，一个分组的名字会对应到一个码点的数组，这个码点数组的范围就是分组的范围。在Unicode5.2的表格里面一共有4258个码点区域。因为Unicode 超过65536个码点，每一个范围都需要用两个32位的数字来表示(起点和终点)，或者说总共是34kb的数据。因为大量的范围定义的码点其实都落在65536以内，所以我们这里可以分为两组，一组用16位表示的范围和一组是用32位表示的范围，这样减少总的内存占用到18Kb。

RE2的实现里面支持了大小写不敏感匹配(通过 (?i)开关开启)，按照Unicode5.2的规格：A和a是对应的，Á和á对应，然后even-K和K(Kelvin)对应，S和`ſ` (long s)对应。一共有2061这种特殊指定的字符映射。RE2里面维持一个这样的映射，每一个Unicode的码点映射到下一个比他大但大小写无关的码点上。比如在映射表里面 B 映射到 b，然后 b映射到 B。大部分的这些映射都只涉及两个字符，但也有个别的映射是超过两个的：K 映射到 k, 然后 k 映射到 (Kelvin-symbol)K， 然后  (Kelvin-symbol)K 映射回 K。这个表看起来信息比较冗余，很多重复的关系映射，比如 A 映射到 a, B 映射到 b， 等等。预期把每一个字符做映射，还不如做范围的delta映射：比如把A到Z映射到加上32以后的相应范围，然后a到j映射到减去32的范围，然后k映射到(Kelvin-symbol)K ，等等。这样优化以后的内存占用从2061个映射暂用16Kb，减小到279个映射，暂用3Kb。

RE2里面，没有实现类似Python里面的别名特性，比如u"\N{LATIN SMALL LETER X}" 作为 "x"的别名。即使去掉了这些明显的用户接口级别的问题，必要的内部表格还是需要大约150Kb的数据。



## Testing

我们怎么知道RE2的代码是没有问题的呢？对正则表达式的实现做测试是一个非常复杂艰巨的任务，尤其当代码里面的分支非常多的时候，类似RE2的这种实现。其他的正则库，类似 [Boost](https://svn.boost.org/trac/boost/browser/trunk/libs/regex/test), [PCRE](http://vcs.pcre.org/viewvc/code/trunk/testdata/), 和 [Perl](http://perl5.git.perl.org/perl.git/tree/455f2c6c92e42c1a9e31268cbd491ba661f99882:/t/re) 他们积累了大量的手工维护的测试用例来检查正则表达式的基础功能，但是如果我们要用手工写的方式来对RE2做覆盖测试，我们很快会发现这是一个海量的工程，所以我们必须通过工具生成的方式做一些自动化的测试。

给定一组小的正则表达式，以及相应的链接操作符，指定一个最大的链接数，[RegexpGenerator](http://code.google.com/p/re2/source/browse/re2/testing/regexp_generator.h)会生成所有可能的链接组合。给定一个字母表，和一个最大的长度，[`StringGenerator`](http://code.google.com/p/re2/source/browse/re2/testing/string_generator.h)会生成所有可能的字符串。然后所有生成的正则表达式在每一个生成的字符串上做匹配操作，然后匹配的结果与写的一个基于回溯算法实现的专门用来做测试用的正则表达式版本(通常会直接用PCRE)做比较。因为RE2和PCRE不是在所有测试用例上完全一致，所以还有一个[分析器](http://code.google.com/p/re2/source/browse/re2/mimics_pcre.cc)来检查所有RE2和PCRE不一致的那些情况，这些情况应该存在[Caveats](https://swtch.com/~rsc/regexp/regexp3.html#caveats)里面。除掉了我们已知的那些不匹配的情况外，RE2和PCRE应该在其他情形下有完全一致的输出。

虽然这种穷举的测试用例必须限制运行在小的正则表达式和小的输入字符串上，但是绝大部分的Bug其实都可以通过这些小的测试用例暴露出来。而且这些测试用例也基本覆盖了其他正则表达式引擎手写的那些用例。虽然如此，在RE2里面依然有一个随机的测试用例，通过`RegexpGenerator`和 `StringGenerator`生成一些随机的大的用例来做测试。当然基本不会出现只能再大用例里面才能出现，而小用例测试不到的情况。即便如此，我们维护这份大的用例让他可以正常运转依然是非常有意义的。



## Performance

RE2在小的检索用例上与PCRE不相上下，但是在大的用例上比PCRE要快很多。小的测试用例，我们用毫秒为单位，因为搜索时间基本与输入字符串的大小(通常是10字节)无关。在大的搜索对比上我们采用MB/s为单位，因为这个时候的检索基本与输入字符的大小成比例。

基准测试报告的代码[`re2/testing/regexp_benchmark.cc`](http://code.google.com/p/re2/source/browse/re2/testing/regexp_benchmark.cc)。这个目录[`re2/source/browse/benchlog`](http://code.google.com/p/re2/source/browse/benchlog/)下面有相应的报告(比较的PCRE版本是8.01，写文章时的最新版本)。

**_编译_**，RE2的编译大概比PCRE要慢3到4倍：

| **System**                             | PCRE    | RE2     |
| -------------------------------------- | ------- | ------- |
| AMD Opteron 8214 HE, 2.2 GHz           | 5.8  µs | 14.1 µs |
| Intel Core2 Duo E7200, 2.53 GHz        | 3.8  µs | 10.4 µs |
| Intel Xeon 5150, 2.66 GHz (Mac Pro)    | 5.9 µs  | 21.7 µs |
| Intel Core2 T5600, 1.83 GHz (Mac Mini) | 6.4 µs  | 24.1 µs |

每一个正则表达式的编译时间差异大约在5-10毫秒。这个时间包括了释放解析器和编译器内存的时间。大部分的情景都是正则表达式编译一次，然后进行多次匹配，所以这种情况下，解析编译时间就变得不是那么重要了。

RE2编译以后的对象要比PCRE编译后的对象要大，大概是几KB与几百B的区别。RE2在编译阶段做了更多的正则分析工作，也存储了更加丰富的表达形式。RE2在匹配的过程中也会保存一些状态(逐步建立DFA)，运行一段时间后一个RE2一般会占用到10KB的样子，但是并不会无止尽的随着匹配增加内存暂用。RE2可以限定到一个指定的内存大小(默认是1MB)。

_**全匹配，无子匹配信息**_。我们前面可以看到不同类型的搜索难度是不一样的，并且RE2也会采用不同的实现。这个基准测试是指定大小的随机生成文本上执行`.*$`搜索。下图看到的是一个相对平滑的搜索对比。

![*Speed of searching for .\*$ in random text. (Mac Pro)*](https://swtch.com/~rsc/regexp/regexp3g1.png)

这里RE2使用的是DFA进行搜索。

_**全匹配，one-pass 正则，带子匹配信息，小的输入文本**_。下面的基准测试是在文本"650-253-0001"上执行`([0-9]+)-([0-9]+)-(0-9)+`，并获取相应的三个子匹配：

| System                                 | PCRE   | RE2    |
| -------------------------------------- | ------ | ------ |
| AMD Opteron 8214 HE, 2.2 GHz           | 0.8 µs | 0.5 µs |
| Intel Core2 Duo E7200, 2.53 GHz        | 0.4 µs | 0.3 µs |
| Intel Xeon 5150, 2.66 GHz (Mac Pro)    | 0.6 µs | 0.3 µs |
| Intel Core2 T5600, 1.83 GHz (Mac Mini) | 0.7 µs | 0.4 µs |

RE2采用的是OnePass匹配引擎来执行搜索，避免NFA的滥用。

_**全匹配，模糊正则表达式，子匹配信息，小输入文本**_。如果正则表达式是那种具备不明确可选项的，RE2就不能使用OnePass引擎，但如果正则表达式和输入文本都足够小的时候，RE2是可以用位状态引擎的。这个基准测试是在文本"650-253-0001"上执行`[0-9]+.(.*)`：

| System                                 | PCRE   | RE2    |
| -------------------------------------- | ------ | ------ |
| AMD Opteron 8214 HE, 2.2 GHz           | 0.6 µs | 2.9 µs |
| Intel Core2 Duo E7200, 2.53 GHz        | 0.3 µs | 2.1 µs |
| Intel Xeon 5150, 2.66 GHz (Mac Pro)    | 0.4 µs | 2.3 µs |
| Intel Core2 T5600, 1.83 GHz (Mac Mini) | 0.5 µs | 2.5 µs |

在这里，我可以看到RE2比PCRE要明显慢，因为这里的正则表达式不是OnePass的：因为在遇到数字的时候，他不知道是该继续匹配[0-9]+，还是该匹配'.'。PCRE优化了这种匹配，但当出现输入文本与正则表达式不匹配的情况的时候，运行时会急速的指数增长，即遍是很正常的输入字符的情况下也会导致严重的性能问题。与之对比，RE2就不会出现这种问题，他的运行效率与输入文本和正则表达式的大小只会是一个线性关系。对于小的输入的时候RE2使用位状态来模拟回溯，但在大输入或者大的正则表达式的时候，RE2会回过去使用NFA。

_**部分匹配，无匹配的情形**_。对于部分匹配(无锚点的匹配)，要求匹配引擎考虑输入文本里面的每一个字节位其实输入的情形。PCRE通过一个循环遍历输入文本的每一个字节为起始字节来尝试匹配。RE2实现可以是可以并行匹配的，而且RE2的实现还会对正则表达式进行完整分析，会潜在的增加运行时效率。

这个基准测试在再一个随机的文本上执行`ABCDEFGHIJKLMNOPQRSTUVWXYZ$`检索：

![*Speed of searching for ABCDEFGHIJKLMNOPQRSTUVWXYZ$ in random text*](https://swtch.com/~rsc/regexp/regexp3g2.png)

RE2里面的DFA大部分时间都花在调用memchr查找第一个其实字符A。PCRE也注意到了其实字符A，但似乎没有充分优化。我估计在PCRE里面，除了第一次调用了memchr以后，没有再使用memchr来查找起始字符A。

下一个基准测试要相对难一点点，因为没有起始字符可以通过memchr来查找了。我们在随机字符上执行`[XYZ]ABCDEFGHIJKLMNOPQRSTUVWXYZ$`检索：

![*Speed of searching for [XYZ]ABCDEFGHIJKLMNOPQRSTUVWXYZ$ in random text. (Mac Pro)](https://swtch.com/~rsc/regexp/regexp3g3.png)

PCRE变得不太适合处理这种情况，而RE2的DFA依然在快速的执行他的一次一个字节的匹配循环。

接下来的一个基准测试对PCRE来说非常不适应。执行如下的正则匹配`[ -~]*ABCDEFGHIJKLMNOPQRSTUVWXYZ$`，而且搜寻的文本里面没有相应的匹配字符串，这个时候PCRE为了匹配`[  -~]*`需要以每一个字节位搜寻的起始字节搜寻怎么个输入文本，这种搜寻的时间复杂度是$O(text^2)$。与之对应的是RE2的DFA的时间复杂度依然是线性的，只需要遍历一次文本。

![*Speed of searching for [ -~]\*ABCDEFGHIJKLMNOPQRSTUVWXYZ$ in random text. (Mac Pro)*](https://swtch.com/~rsc/regexp/regexp3g4.png)

_**搜索并解析**_。另外一个RE的典型应用场景就是搜索和解析文本里面出现的特定字符串。这个基准测试会产生一个随机字符串，然后把 "(650 253-0001)"附加在随机字符串后面，然后在这个生成的文本上执行如下的无锚点匹配`(\d{3}-|\(\d{3}\)\s+)(\d{3}-\d{4})`，找到相应的7位电话号码，并提前相应的区位代码。

![*Speed of searching for and matching (\d{3}-|\(\d{3}\\)\s+)(\d{3}-\d{4}) in random text ending wtih (650) 253-0001. (Mac Pro)*](https://swtch.com/~rsc/regexp/regexp3g5.png)

RE2的快速主要归功于DFA提供的线性搜索能力。

_**总结**_。RE2对每一个正则表达式需要10KB左右的内存占用，与之对应的PCRE只要需要0.5KB或者更少。与内存占用对应的是，RE2保障线性时间复杂度的搜索性能(虽然这里的线性参照值是根据情况而不同的)。

在单纯查询一个字符串是否和一个正则表达式匹配的时候，RE2和PCRE的运行效率是等价的(对于RE2来说，就是无任何参数调用RE2::FullMatch和RE2::PartialMatch的情况)。

对于模糊正则表达式去解析文本的情况，RE2和PCRE的运行效率也是等价的。而且在查询一些短文本匹配的时候，RE2的运行时间大约是PCRE的两倍，而且当查询一些长文本的时候应该是更慢的。但是回过来说，模糊正则匹配的使用情况，通常数据都不大，而且通常应用场景里面这个匹配过程不是整个场景的效率瓶颈所在(比如，分析一个文件名的性能损失与发开这个文件所需的时间进行对比的话几乎是微不足道的，从前面的基准测试，我们能知道文件名的这种短文本的单个匹配基本在纳秒级别)。

RE2比较擅长的是在一个巨量的文本上进行搜索，同时找出相应的匹配串的时候；如果相应的正则搜索还需要到PCRE进行递归回溯，那么RE2的效率提升就会特别明显了。

上面的基准测试，主要是与PCRE进行比较，因为这两者比较非常直接：首先他们都是C/C++实现，其次两者连接口都基本一致。这里还需要特别强调一下的是，这里的基准测试主要比较的是算法的差异，而不是比较两者的性能调优。PCRE采用的算法，主要是为了全面兼容Perl或者类Perl的正则引擎(大部分情况下的算法选择也就会局限于此)。



## Caveats

RE2明确表达了，他不会尝试去支持所有Perl提出的那些正则特性。RE2支持的Perl特性有：支持非贪婪的repetition；支持字符分类类似\d；支持空断言 类似 \A, \b, \B和\z。RE2不支持前向或者后向断言，也不支持后向引用。RE2支持计数的repetition，但他的实现是通过展开正则表达式来桌的(`\d{3}`会被展开为`\d\d\d`)，所以在RE2里面计数通常不要搞太大。RE2也支持Python风格的`(?P<name>expr)`命名捕获，但不支持Perl或者.Net里面的`(?<name>expr)`和`(?'name'expr)`这种命名语法。

RE2在匹配行为上与PCRE也不是完全一致。这里有一些已知的差异点：

* 如果正则表达式包含一个空字符串的重复的正则，类似`(a*)+`，这种情况下PCRE会把重复序列当做空字符串来处理，而RE2不是这样。比如当用`(a*)+`来匹配`aaa`的时候，PCRE会运行两次`+`操作来匹配`aaa`，然后再运行一次`+`来匹配一个空字符串；而RE2只会运行`+`一次，来匹配`aaa`，因为在RE2里面，括号里面的正则表达式已经匹配了尽可能长的文本；也就是在这种情况下，PCRE的`$1`是一个空字符串，而RE2`$2`是`aaa`。当然如果需要PCRE的这种行为也是可以撮到RE2里面去的，但笔者认为是没有必要的。
* Perl和PCRE对于`\v`的语义是不一样的。在Perl里面这个只匹配垂直的Tab字符（VT，0x0B)，而在PCRE里面他会同时匹配垂直Tab和换行。这个地方RE2选择和Perl保持一致。
* 在单行模式下，如果输入文本最后是一个换行符，Perl和PCRE是允许用一个`$`来匹配包含或者不包含换行符的。RE2就一定是包含了换行符的。
* 类似在多行模式下，如果输入文本是以换行符结束的，Perl和PCRE是不支持用`^`来匹配行开始处的换行符。但RE2是可以的。
* RE2没有支持完整的Unicode的所有分类，但是实现了基本的Unicode属性类。
* 在UTF-8模式下，PCRE定义了不属于POSIX标准的分类 `[[:^xxx:]]`单独用来匹配ASCII码点，所以`[[:^alpha:]]`匹配所以不属于`[[:alpha]]`的ASCII字符，而`[^[:alpha:]]`用来匹配所以不属于`[[:alpha:]]`的Unicode字符。RE2纠正了这个不一致：`[[:^alpha:]]`和`[^[:alpha:]]`都是匹配不属于`[[:alpha:]]`的所有Unicode字符。

还有一部分Perl和PCRE里面笔者看起来比较晦涩的特性，RE2选择不支持的：

* ​



























